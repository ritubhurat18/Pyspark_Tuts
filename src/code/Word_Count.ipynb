{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa595232-cefd-4f60-81b5-0780cb8db4c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Pyspark Word Count Program \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "800405ca-d248-4556-8268-ecdae6ac0148",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "spark = SparkSession.builder.appName(\"Pyspark Word Count\").getOrCreate()\n",
    "txt = \"Hello hello Reetu, Here's your First@ Word Count Program in Spark for count word!\"\n",
    "df = spark.createDataFrame([txt], StringType())\n",
    "\n",
    "\n",
    "def clean_text(df):\n",
    "    clean_df = df.\\\n",
    "        select(F.lower(F.regexp_replace(df.value,\"[^A-Za-z0-9\\\\s\\'$]\",\"\"))\\\n",
    "        .alias(\"cleaned_value\"))\n",
    "    return clean_df\n",
    "\n",
    "def word_count(df):\n",
    "    split_df = df.\\\n",
    "        select(F.split(F.col(\"cleaned_value\"),\" \").alias(\"splitted_value\")).\\\n",
    "        select(F.explode(F.col(\"splitted_value\")).alias(\"word\"))\n",
    "    word_count = split_df.\\\n",
    "        groupBy(split_df.word).agg(F.count(split_df.word).alias(\"count\"))\n",
    "    return word_count\n",
    "\n",
    "clean_df = clean_text(df)\n",
    "clean_df.show(truncate=False)\n",
    "word_count_df = word_count(clean_df)\n",
    "word_count_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33d89736-434f-4b5f-aa0e-e4288c1e1aec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Installing Pytest\n",
    "%pip install pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae0f142e-9c0a-4dad-80d1-4dfb770f5400",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f1acc94-bcba-4d2c-833b-ffcfa78b0d1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "def test_add():\n",
    "    assert add(1, 2) == 3\n",
    "    assert add(1, 1) == 2"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Word_Count",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
